{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NamesDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer: T5Tokenizer,\n",
    "        data_path: str,\n",
    "        max_length: int = 20,\n",
    "        truncation: bool = True\n",
    "    ) -> None:\n",
    "        self.tokenizer = tokenizer\n",
    "        self.truncation = truncation\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        with open(data_path, encoding=\"utf-8\") as json_data:\n",
    "            self.data = json.load(json_data)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        name = self.data[index][\"name\"]\n",
    "        body = self.data[index][\"body\"]\n",
    "        \n",
    "        tokens = self.tokenizer(\n",
    "            name,\n",
    "            return_tensors='pt',\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            truncation=self.truncation\n",
    "        )\n",
    "        \n",
    "        labels = self.tokenizer(\n",
    "            body,\n",
    "            return_tensors='pt',\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            truncation=self.truncation\n",
    "        ).input_ids\n",
    "        \n",
    "        labels = labels.masked_fill_(labels == 0, -100) \n",
    "        \n",
    "        return name, body, tokens.input_ids[0], tokens.attention_mask[0], labels[0]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return  len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "MODEL_TYPE = \"base\"\n",
    "\n",
    "if MODEL_TYPE not in [\"large\", \"base\", \"small\"]:\n",
    "    raise ValueError(\"Wrong size of model type\")\n",
    "\n",
    "MODEL_NAME = \"sberbank-ai/ruT5-\" + MODEL_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = {\n",
    "    \"lr\": 1e-3,\n",
    "    \"epoch_num\": 100,\n",
    "    \"opt\": \"Adam\",\n",
    "    \"batch_size\": 2,\n",
    "    \"lr_decay\": 0.8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NamesDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    data_path=\"../data/name_slogan.json\"\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=training_config[\"batch_size\"], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_work():\n",
    "    name, body, _, _, _ = dataset[5]\n",
    "    \n",
    "    name = \"Михаил\"\n",
    "    body = \"Вообще дебил\"\n",
    "    \n",
    "    print(name)\n",
    "    print(body)\n",
    "    \n",
    "    tokens = tokenizer(name, return_tensors='pt', padding=\"max_length\", max_length=40, truncation=True).to(DEVICE)\n",
    "    labels = tokenizer(body, return_tensors='pt', padding=\"max_length\", max_length=40, truncation=True).input_ids.to(DEVICE)\n",
    "    labels = labels.masked_fill_(labels == 0, -100) \n",
    "    \n",
    "    output=model(\n",
    "        input_ids=tokens.input_ids,\n",
    "        attention_mask=tokens.attention_mask,\n",
    "        labels=labels\n",
    "    )\n",
    "    \n",
    "    print(output[\"loss\"])\n",
    "    print(tokenizer.batch_decode(torch.argmax(output[\"logits\"], dim=2).to(\"cpu\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Михаил\n",
      "Вообще дебил\n",
      "tensor(16.1739, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "['Будь «твор с Вер Будь Будь Будь Будь Будь Будь Будь Будь Будь Будь Будь Будь Будь Будь Будь Будь Будь Будь Будь Будь Будь Будь Будь Будь Будь Будь Будь Будь Будь Будь Будь Будь Будь Будь Будь']\n"
     ]
    }
   ],
   "source": [
    "test_work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num = training_config[\"epoch_num\"]\n",
    "model.train()\n",
    "opt = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=training_config[\"lr\"]\n",
    ")\n",
    "\n",
    "lambda1 = lambda epoch: training_config[\"lr_decay\"] ** epoch\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(opt, lr_lambda=lambda1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ddb503d24c742468e86fb50b8232fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc1f9764983496dae9211f3ce0dc101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca6f534bdcf417d9919b9ec3bd29d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab4552c4ab0f453e8337423c34742672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01b6baeb4e241a8a09c7f03ce79eba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d751109d6b42918bdd85f5133bf5fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4137453b24c498b90a9d4887028a49a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127291065de64af1812378056d52c7c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65894ea0556c41928c79229beb42bc1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f07e35e7600541d4aaeb2d762843c866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4080415d62f34af9aa0017925bd8a851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a50095882e42e7a6175332d577fd8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93c8bef2f03e43309890b0864e623683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc84cb68b7f4d33991f50af68e78648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad238c9236e743a5860813777d030323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b704d1e97f5742b1b98edb9a47b7c0a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259542b5281246d5b78b477d1c65acad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7076c4e433ee418bbe0d4b2a03cca270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0137707475a4dde94df4aa1f54343ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 12\u001b[0m\n\u001b[0;32m      4\u001b[0m model\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m      6\u001b[0m output\u001b[39m=\u001b[39mmodel(\n\u001b[0;32m      7\u001b[0m     input_ids\u001b[39m=\u001b[39mtokens_ids\u001b[39m.\u001b[39mto(DEVICE),\n\u001b[0;32m      8\u001b[0m     attention_mask\u001b[39m=\u001b[39mtokens_attention\u001b[39m.\u001b[39mto(DEVICE),\n\u001b[0;32m      9\u001b[0m     labels\u001b[39m=\u001b[39mlabels\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[0;32m     10\u001b[0m )\n\u001b[1;32m---> 12\u001b[0m output[\u001b[39m\"\u001b[39;49m\u001b[39mloss\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     14\u001b[0m loss_value \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mloss\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     15\u001b[0m writer\u001b[39m.\u001b[39madd_scalar(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoss \u001b[39m\u001b[39m{\u001b[39;00mtraining_config\u001b[39m=}\u001b[39;00m\u001b[39m\"\u001b[39m, loss_value, iter_num)\n",
      "File \u001b[1;32mc:\\Max\\Proga\\python_venv\\.venv\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Max\\Proga\\python_venv\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iter_num = 0 \n",
    "for epoch in range(epoch_num):\n",
    "    for _, _, tokens_ids, tokens_attention, labels in tqdm(dataloader, total=len(dataset)):\n",
    "        model.zero_grad()\n",
    "        \n",
    "        output=model(\n",
    "            input_ids=tokens_ids.to(DEVICE),\n",
    "            attention_mask=tokens_attention.to(DEVICE),\n",
    "            labels=labels.to(DEVICE)\n",
    "        )\n",
    "        \n",
    "        output[\"loss\"].backward()\n",
    "        \n",
    "        loss_value = output.loss.detach().cpu().item()\n",
    "        writer.add_scalar(f\"Loss {training_config=}\", loss_value, iter_num)\n",
    "        opt.step()\n",
    "        iter_num += 1\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
